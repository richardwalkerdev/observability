== Using Ansible

It obvious that all this manual implementation is not very practical, and sure, there are Ansible Roles available on Ansible Galaxy to deploy most of this stuff. That said, understanding the requirements close up and personally paves the way to automate this yourself. I tend to use Ansible in this way from my client Linux laptop, it might be an idea to do it on the utilities host in this scenario!

=== Remote Hosts

These steps need to be repeated on any host intended to be managed by Ansible. To use a user account called "ansible" and become root, it helps in `/etc/sudoers` to allow `sudo` with no password, on each node to be managed by Ansible. For example:

[source%nowrap,bash]
----
visudo
----

[source%nowrap,bash]
----
## Allows people in group wheel to run all commands
#%wheel	ALL=(ALL)	ALL

## Same thing without a password
%wheel	ALL=(ALL)	NOPASSWD: ALL
----

Add that user on remote hosts make them a member of the `wheel` group:

[source%nowrap,bash]
----
useradd ansible
passwd ansible
usermod -aG wheel ansible
----

=== Quick Install

Create a new working directory:

[source%nowrap,bash]
----
mkdir ansible && cd ansible
----

Create a new Python 3 Virtual Environment:

[source%nowrap,bash]
----
python3 -m venv venv
----

Activate the Python environment:

[source%nowrap,bash]
----
source venv/bin/activate
----

Make sure `pip` is updated:

[source%nowrap,bash]
----
pip install --upgrade pip
----

Install Ansible:

[source%nowrap,bash]
----
pip install ansible
----

=== Get Started

Make the directory skeleton:

[source%nowrap,bash]
----
mkdir -p inventories/lab playbooks/lab roles
----

Add the IP Address of any host needed to be managed by Ansible, in this case in the `lab` inventory:

[source%nowrap,bash]
----
vi inventories/lab/hosts
----

[source%nowrap,bash]
----
192.168.0.70
192.168.0.71
192.168.0.72

[monitoring_servers]
192.168.0.71
192.168.0.72
----

Add an `ansible.cfg` file in the `playbooks/lab` directory:

[source%nowrap,bash]
----
vi playbooks/lab/ansible.cfg
----

[source%nowrap,bash]
----
[defaults]
inventory = ../../inventories/lab
roles_path = ../../roles
host_key_checking = False
retry_files_enabled = False
command_warnings = False
remote_user = ansible
----

Create a basic smoke test role:

[source%nowrap,bash]
----
mkdir -p roles/smoke_test/tasks roles/smoke_test/defaults
----

Add a default variable:

[source%nowrap,bash]
----
vi roles/smoke_test/defaults/main.yml
----

[source%nowrap,yaml]
----
---
message: 'Hello World!'
----

Add a basic task to the role:

[source%nowrap,bash]
----
vi roles/smoke_test/tasks/main.yml
----

[source%nowrap,yaml]
----
---
- name: Smoke test
  shell: echo "{{ message }}" > /tmp/smoke_test.yml
----

Add a playbook for the smoke test, this example if for a single server:

[source%nowrap,bash]
----
vi playbooks/lab/smoke_test.yml
----

[source%nowrap,yaml]
----
---
- name: Smoke Test Playbook
  hosts: 192.168.0.71
  remote_user: ansible
  become: yes
  roles:
    - smoke_test
----

Or target the group of hosts:

[source%nowrap,yaml]
----
---
- name: Smoke Test Playbook
  hosts: monitoring_servers
  remote_user: ansible
  become: yes
  roles:
    - smoke_test
----

Move into the `playbooks/lab/` directory:

[source%nowrap,bash]
----
cd playbooks/lab/
----

Copy your ID to the target server/s, in this example `ansible`:

[source%nowrap,bash]
----
ssh-copy-id ansible@192.168.0.71
ssh-copy-id ansible@192.168.0.72
----

Run the smoke test playbook:

[source%nowrap,bash]
----
ansible-playbook smoke_test.yml
----

=== Working with Facts

Its useful to list facts for when define conditions on certain tasks, here is an example:

[source%nowrap,bash]
----
ansible all -m setup -a "filter=ansible_distribution*
----

=== Group Vars

Create a directory for the lab inventory called `group_vars` which will hold parameters that apply to the `monitoring_servers` group. This group includes `192.168.0.71` and `192.168.0.72`, paramters will apply to both these servers.

[source%nowrap,bash]
----
mkdir -p inventories/lab/group_vars
----

[source%nowrap,bash]
----
vi inventories/lab/group_vars/monitoring_servers.yml
----

[source%nowrap,yaml]
----
---
message: 'Hello World from group_vars!'
----

Run the smoke test playbook again and see that the group variables override the defaults:

[source%nowrap,bash]
----
ansible-playbook smoke_test.yml
----

=== Add Roles

I create a role for each component from scratch to keep things a simple and minimalistic as possible. Mature roles are available from Ansible Galaxy for example:

* https://galaxy.ansible.com/cloudalchemy/prometheus
* https://galaxy.ansible.com/cloudalchemy/node_exporter
* https://galaxy.ansible.com/cloudalchemy/alertmanager
* https://galaxy.ansible.com/cloudalchemy/grafana

I still prefer to create them from scratch while getting to grips with things before adopting community versions.

You can clone my Ansible repo here https://github.com/richardwalkerdev/observability-ansible-lab.git

The only steps needed are to create the Python virtual environment with Ansible installed, activated and update the following to your needs:

[source%nowrap,bash]
----
vi inventories/lab/group_vars/monitoring_servers.yml
----


[source%nowrap,yaml]
----
alertmanager_cluster_peers:
  - '192.168.0.71'
  - '192.168.0.72'

thanos_store_stores:
  - 192.168.0.71:10905
  - 192.168.0.72:10905

thanos_store_sidecars:
  - 192.168.0.71:10901
  - 192.168.0.72:10901

grafana_db_host     : '192.168.0.70:5432'
grafana_db_name     : 'grafana_db'
grafana_db_user     : 'grafana'
grafana_db_password : 'changeme'
----

Change into the `playbooks/lab/` directory, ensure `ansible.cfg` is correct and run:

[source%nowrap,bash]
----
ansible-playbook deploy_all.yml
----


// This is a comment and won't be rendered.
